{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from scene_edit_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haoweis/.conda/envs/drivestudio/lib/python3.9/site-packages/torch/cuda/__init__.py:209: UserWarning: \n",
      "NVIDIA H100 80GB HBM3 with CUDA capability sm_90 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_35 sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_89 compute_89.\n",
      "If you want to use the NVIDIA H100 80GB HBM3 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n",
      "Loading images: 100%|██████████| 31/31 [00:00<00:00, 47.51it/s]\n",
      "Loading dynamic masks: 100%|██████████| 31/31 [00:00<00:00, 110.02it/s]\n",
      "Loading human masks: 100%|██████████| 31/31 [00:00<00:00, 116.42it/s]\n",
      "Loading vehicle masks: 100%|██████████| 31/31 [00:00<00:00, 110.08it/s]\n",
      "Loading sky masks: 100%|██████████| 31/31 [00:00<00:00, 221.06it/s]\n",
      "Loading images: 100%|██████████| 31/31 [00:00<00:00, 49.34it/s]\n",
      "Loading dynamic masks: 100%|██████████| 31/31 [00:00<00:00, 110.11it/s]\n",
      "Loading human masks: 100%|██████████| 31/31 [00:00<00:00, 114.35it/s]\n",
      "Loading vehicle masks: 100%|██████████| 31/31 [00:00<00:00, 110.72it/s]\n",
      "Loading sky masks: 100%|██████████| 31/31 [00:00<00:00, 235.98it/s]\n",
      "Loading images: 100%|██████████| 31/31 [00:00<00:00, 46.10it/s]\n",
      "Loading dynamic masks: 100%|██████████| 31/31 [00:00<00:00, 114.75it/s]\n",
      "Loading human masks: 100%|██████████| 31/31 [00:00<00:00, 115.13it/s]\n",
      "Loading vehicle masks: 100%|██████████| 31/31 [00:00<00:00, 116.24it/s]\n",
      "Loading sky masks: 100%|██████████| 31/31 [00:00<00:00, 225.21it/s]\n",
      "Loading SMPL: 100%|██████████| 31/31 [00:00<00:00, 840.48it/s]\n",
      "Loading lidar:   0%|          | 0/31 [00:00<?, ?it/s]/home/haoweis/drivestudio/datasets/nuplan/nuplan_sourceloader.py:408: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1718580525958/work/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  lidar_points = torch.from_numpy(lidar_info[:, :3]).float()\n",
      "Loading lidar: 100%|██████████| 31/31 [00:00<00:00, 79.83it/s]\n",
      "Projecting lidar pts on images for camera CAM_F0: 100%|██████████| 31/31 [00:02<00:00, 14.54it/s]\n",
      "Projecting lidar pts on images for camera CAM_L0: 100%|██████████| 31/31 [00:00<00:00, 671.36it/s]\n",
      "Projecting lidar pts on images for camera CAM_R0: 100%|██████████| 31/31 [00:00<00:00, 747.15it/s]\n",
      "/home/haoweis/.conda/envs/drivestudio/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/haoweis/.conda/envs/drivestudio/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/haoweis/chumpy/chumpy/ch_ops.py:85: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  assert(order is 'C' or order is None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using predefined pose: da_pose\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "example_idx = \"2021.05.12.22.00.38_veh-35_01008_01518\"\n",
    "\n",
    "folder_path = \"output/nuplan_example/\" + example_idx\n",
    "\n",
    "resume_from = folder_path + \"/checkpoint_final.pth\"\n",
    "new_checkpoint_path = folder_path + \"/checkpoint_edit.pth\"\n",
    "\n",
    "trainer_01518 = load_trainer(resume_from)\n",
    "rigid_01518 = trainer_01518.models['RigidNodes']\n",
    "print(torch.unique(rigid_01518.point_ids[..., 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 19, 3])\n"
     ]
    }
   ],
   "source": [
    "print(rigid_01518.instances_trans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_idx = \"023\"\n",
    "\n",
    "folder_path = \"output/waymo_example/idx_\" + example_idx\n",
    "\n",
    "resume_from = folder_path + \"/checkpoint_final.pth\"\n",
    "new_checkpoint_path = folder_path + \"/checkpoint_edit.pth\"\n",
    "\n",
    "trainer_023 = load_trainer(resume_from)\n",
    "rigid_023 = trainer_023.models['RigidNodes']\n",
    "print(torch.unique(rigid_023.point_ids[..., 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_idx = \"327\"\n",
    "\n",
    "folder_path = \"output/waymo_example/idx_\" + example_idx\n",
    "\n",
    "resume_from = folder_path + \"/checkpoint_final.pth\"\n",
    "new_checkpoint_path = folder_path + \"/checkpoint_edit.pth\"\n",
    "\n",
    "trainer_327 = load_trainer(resume_from)\n",
    "rigid_327 = trainer_327.models['RigidNodes']\n",
    "print(torch.unique(rigid_327.point_ids[..., 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#rigid_023 = transfer_veh(rigid_023, rigid_327, 1)\n",
    "\n",
    "new_trans = rigid_023.instances_trans[:, 6].cpu().detach().numpy()\n",
    "\n",
    "new_trans[:, 0] = np.array([new_trans[0, 0]]*len(new_trans))\n",
    "#new_trans[:, 1] = np.array([new_trans[0, 1]]*len(new_trans))\n",
    "\n",
    "rigid_023 = change_trans(rigid_023, 6, torch.tensor(new_trans, device='cuda:0', requires_grad=True).view(len(new_trans), 3))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rigid_01518 = change_trans_gradual(rigid_01518, 2, 0, 30, [5.2243e+01, -2.7e+00, 3.0053e-03])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rigid_01518.instances_trans[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "example_idx = \"2021.05.12.22.00.38_veh-35_01008_01518\"\n",
    "\n",
    "folder_path = \"output/nuplan_example/\" + example_idx\n",
    "\n",
    "resume_from = folder_path + \"/checkpoint_final.pth\"\n",
    "new_checkpoint_path = folder_path + \"/checkpoint_edit.pth\"\n",
    "\"\"\"\n",
    "save_checkpoint(trainer_01518, new_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_trans = np.array([[10.0, -10.0, 0.0]]*len(rigid_327.instances_trans[:, 0].cpu().detach().numpy()))\n",
    "rigid_327 = change_trans(rigid_327, 2, torch.tensor(new_trans, device='cuda:0', requires_grad=True).view(len(new_trans), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_023 = trainer_023.models[\"Background\"]\n",
    "background_327 = trainer_327.models[\"Background\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_327._means # xzy means of gaussian points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rigid_327.instances_size[0] # xyz size of a vehicle\n",
    "rigid_327.instances_trans[:, 0] # xyz location of center of bounding box, so lowest point would be z_box - z_size/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_327.scene_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = background_327._means.cpu().detach().numpy()\n",
    "test_scales = background_327._scales.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_first_column = test[np.argsort(test[:, 0])]\n",
    "sorted_by_second_column = test[np.argsort(test[:, 1])]\n",
    "\n",
    "# Retrieve entries in the second array where the y values (second column) are between -10.5 and -9.5\n",
    "filtered_by_y = sorted_by_second_column[(sorted_by_second_column[:, 1] > -10.001) & (sorted_by_second_column[:, 1] < -9.999)]\n",
    "\n",
    "# Retrieve entries in the first array where the x values (first column) are between 9.5 and 10.5\n",
    "filtered_by_x = sorted_by_first_column[(sorted_by_first_column[:, 0] > 9.999) & (sorted_by_first_column[:, 0] < 10.001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_by_xy = test[(test[:, 0] > 9.8) & (test[:, 0] < 10.2) & (test[:, 1] > -0.2) & (test[:, 1] < 0.2)]\n",
    "filtered_by_xy = filtered_by_xy[np.argsort(filtered_by_xy[:, 2])]\n",
    "\n",
    "# Calculate the Euclidean distance to the point (10, -10) for each entry\n",
    "distances = np.sqrt((filtered_by_xy[:, 0] - 10)**2 + (filtered_by_xy[:, 1] + 10)**2)\n",
    "\n",
    "# Find the index of the minimum distance\n",
    "min_index = np.argmin(distances)\n",
    "\n",
    "# Select the entry closest to (10, -10)\n",
    "closest_entry = filtered_by_xy[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rigid_327._scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drivestudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
